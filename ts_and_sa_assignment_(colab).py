# -*- coding: utf-8 -*-
"""TS_and_SA_assignment_(colab).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F921etD0zAypY_IPirs2dhzdulmcuslF

##### Import
"""

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import tensorflow as tf
import keras

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import accuracy_score, mean_absolute_error

from keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from keras.layers import Dense, Embedding, LSTM, Dropout

"""---
# Time Series Analysis on Avocado Data

In this project, I shall be performing analysis on Avocado price data, using three variations of a LSTM neural network.

*   Model 1: Single LSTM layer
*   Model 2: Two LSTM layers
*   Model 3: Three LSTM layers

The table below represents weekly 2018 retail scan data for National retail volume (units) and price. Retail scan data comes directly from retailers’ cash registers based on actual retail sales of Hass avocados. Starting in 2013, the table below reflects an expanded, multi-outlet retail data set. Multi-outlet reporting includes an aggregation of the following channels: grocery, mass, club, drug, dollar, and military. The Average Price (of avocados) in the table reflects a per unit (per avocado) cost, even when multiple units (avocados) are sold in bags. The Product Lookup codes (PLU’s) in the table are only for Hass avocados. Other varieties of avocados (e.g. greenskins) are not included in this table.

Some relevant columns in the dataset:

*   Date - The date of the observation
*   AveragePrice - the average price of a single avocado
*   type - conventional or organic
*   year - the year
*   Region - the city or region of the observation
*   Total Volume - Total number of avocados sold
*   4046 - Total number of avocados with PLU 4046 sold
*   4225 - Total number of avocados with PLU 4225 sold
*   4770 - Total number of avocados with PLU 4770 sold

The dataset is available at; https://www.kaggle.com/neuromusic/avocado-prices
"""

#import CSV to dataframe
data = pd.read_csv('/content/avocado.csv', index_col=None, header=0)
data.head()

"""We seem to have one redundent columns called "unnamed" (possibly used as an ID field), but a mixture of Int, Float and Object types. A break down of which can be seen below."""

data.info()

"""Before working with the data, lets check if it needs to be cleaned. We shall do this by Checking for null rows or for duplicate values.

(Spoiler: no missing values, no duplicate entries)


"""

#Count missing values in each column.
data.isna().sum()

#duplicate values check
data.duplicated().sum()
data.loc[data.duplicated(keep=False),:]

"""Since we are only focusing on Average Price, we can drop all the other columns, I have reffered to below project for the train/test splitting process, and use of the function "make_feed_dicts"; https://www.kaggle.com/hastok/lstm-avocado-price-prediction"""

data = data.drop(['Unnamed: 0', 'Date', 'Total Volume', '4046', '4225', '4770', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', 'type', 'year', 'region'],1)

#scale dataet
scaler = StandardScaler()
data = scaler.fit_transform(data)

#function defined for train/test split
#90% training, 10% test
def make_feed_dicts(data,hist_len):
    xs,ys = [],[]
    for i in range(len(data)-hist_len-1):
        ys.append(data[i+hist_len])
        xs.append(data[i:i+hist_len])
    j = int(len(data)*0.9)
    return np.array(xs[:j]),np.array(xs[j:]),np.array(ys[:j]),np.array(ys[j:])

scale_min = min(data)
scale_range = max(data) - scale_min

hist_len = 10
x_train, x_test, y_train, y_test = make_feed_dicts(data, hist_len)
x_test.shape

"""Looking at our x_test dataframe for an example, we have a single dimension frame, with 1814 values in a shape of 10.

Let's feed our three models with our test/train data split. Where each model has an added LSTM layer to compare and evaluate if adding more layers increased the accuracy of our prediciton (while maintaining a low loss). In model two and model three, I have introduced drop out layers between the additional LSTM layers.

---
# Model One: Single LSTM
"""

# Define the Keras model
model1 = Sequential()

model1.add(LSTM(256, input_shape=(hist_len, 1)))

model1.add(Dense(5, activation='sigmoid'))
model1.add(Dense(1, activation='sigmoid'))

model1.compile(loss='mean_squared_error', optimizer='adam')

# Give a summary
model1.summary()

history1 = model1.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test),shuffle=False)

plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])

"""Using a single LSTM layer produeces low losses, well relaively, and the curve which represents this is smooth. Can we reduce or improve the loss curve?!

Below represents the accuracy of of our predictions against our actual values, they seem to show relative consitancy and apear to somewhat represent the actual values. However, the predicted values do not as closely follow the magnitude of the actual values, the direction does seem to be consistant.


"""

predicted_x = model1.predict(x_test[:250])
plt.plot(predicted_x*scale_range+scale_min)
plt.plot(y_test[:250].reshape(-1,1)*scale_range+scale_min)

"""---
# Model Two: Two LSTMs
"""

# Define the Keras model
model2 = Sequential()

model2.add(LSTM(256, input_shape=(hist_len, 1), return_sequences=True))
model2.add(Dropout(0.1))

model2.add(LSTM(256, input_shape=(hist_len, 1)))
model2.add(Dropout(0.1))

model2.add(Dense(5, activation='sigmoid'))
model2.add(Dense(1, activation='sigmoid'))

model2.compile(loss='mean_squared_error', optimizer='adam')

# Give a summary
model2.summary()

history2 = model2.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test),shuffle=False)

plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])

"""For this model I have changed the epochs and increased them to 15 since initial testing with 10 Epochs hadn't created much visible change in comparison to model one. When the Epochs were kept at 10, the loss and valdiation curve were smoothend. With an increase to 15 we can we a sharp upspike on the 5th Epoch but normalises by the 6th. However, the final loss value is no different to model one or setting Epochs to 10.

Apart from the smoothend loss and loss validation curves, there is not much increase in accuracy which is substantially different than the use of a single layer LSTM. Below represents the accuracy of of our predictions against our actual values. Again, the below graph is very similar to model one, the predicted values do not as closesly follow the magnitude of the actual values, the direction does seem to be consistant.
"""

predicted_x = model2.predict(x_test[:250])
plt.plot(predicted_x*scale_range+scale_min)
plt.plot(y_test[:250].reshape(-1,1)*scale_range+scale_min)

"""---
# Model Three: Three LSTMs
"""

# Define the Keras model
model3 = Sequential()

model3.add(LSTM(256, input_shape=(hist_len, 1), return_sequences=True))
model3.add(Dropout(0.1))

model3.add(LSTM(256, input_shape=(hist_len, 1), return_sequences=True))
model3.add(Dropout(0.1))

model3.add(LSTM(256, input_shape=(hist_len, 1)))
model3.add(Dropout(0.1))

model3.add(Dense(5, activation='sigmoid'))
model3.add(Dense(1, activation='sigmoid'))

model3.compile(loss='mean_squared_error', optimizer='adam')

# Give a summary
model3.summary()

history3 = model3.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test),shuffle=False)

plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])

"""Can a three LSTM layers create any difference?!

With our loss and loss validation curves, there doesnt seem to be as an apparent change, howeverm it seems that our predicted and actual graph below has improved, where the predicited line is following the actualy curve much more closely than model one or model two. However, the predicted does not follow the same magnitude as the actual values.
"""

predicted_x = model3.predict(x_test[:250])
plt.plot(predicted_x*scale_range+scale_min)
plt.plot(y_test[:250].reshape(-1,1)*scale_range+scale_min)

"""---
# Summery

Initially it seemed that a single LSTM layer was sufficient, though, the predicted results are too smooth and dont follow the actual results as well as model three. However, all models come short when reproducing the magnitude of the prediction with the actual results. This is possibly due to the loss being relativly high (especially with model two). If it wasnt for this, then model three would be perfect, however, I feeel that there is scope of improvement in reducing the loss of each model.

It can be said though, that adding more complexity to the model does yeild better prediciton, but this does add to longer trining times, and to what degree will adding more comlexity leade to over-complexity.


It would then be best suggested to stick to model one, though, it would be of benefit to find out if optimising the LSTM nodes themselves can make a difference with the multi-layered nodes. For example, do we need less nodes as we increase the LSTM layers?! Or do we need to optimise our dropout layer or even experiment with a different loss/optimiser algorithm?!

Considering my approach was just focused on average price, was there a different mean I could take from it, maybe involve some other measurement metric?!
"""